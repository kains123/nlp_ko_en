{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word-level 번역기(Neural Machine Translation).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlz9NZ8DJYzt"
      },
      "source": [
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import urllib3\n",
        "import zipfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "075ZXDGfJzLk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d22360f6-3181-4ca4-fde9-228afb08da4a"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Korpora\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjxVpmIcc8OV",
        "outputId": "cdb30af8-9219-43bf-a429-b196aab8bc13"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Korpora in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: tqdm>=4.46.0 in /usr/local/lib/python3.7/dist-packages (from Korpora) (4.62.3)\n",
            "Requirement already satisfied: dataclasses>=0.6 in /usr/local/lib/python3.7/dist-packages (from Korpora) (0.6)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from Korpora) (2.23.0)\n",
            "Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from Korpora) (2.0.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from Korpora) (1.19.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->Korpora) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->Korpora) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->Korpora) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->Korpora) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i14IPvoBJNLm"
      },
      "source": [
        "num_samples = 33000"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Korpora import Korpora\n",
        "Korpora.corpus_list()\n",
        "corpus = Korpora.load('open_subtitles')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB-opARQc-H6",
        "outputId": "f4b7b46c-7b16-4ae0-b8b8-b3787334f617"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
            "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
            "\n",
            "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
            "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
            "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
            "\n",
            "    # Description\n",
            "    Author : TRAC (https://trac.edgewall.org/)\n",
            "    Repository : http://opus.nlpl.eu/OpenSubtitles-v2018.php\n",
            "    References :\n",
            "        - P. Lison and J. Tiedemann, 2016, OpenSubtitles2016: Extracting Large Parallel Corpora\n",
            "          from Movie and TV Subtitles. In Proceedings of the 10th International Conference on\n",
            "          Language Resources and Evaluation (LREC 2016)\n",
            "\n",
            "    This is a new collection of translated movie subtitles from http://www.opensubtitles.org/.\n",
            "\n",
            "    [[ IMPORTANT ]]\n",
            "    If you use the OpenSubtitle corpus: Please, add a link to http://www.opensubtitles.org/\n",
            "    to your website and to your reports and publications produced with the data!\n",
            "    I promised this when I got the data from the providers of that website!\n",
            "\n",
            "    This is a slightly cleaner version of the subtitle collection using improved sentence alignment\n",
            "    and better language checking.\n",
            "\n",
            "    62 languages, 1,782 bitexts\n",
            "    total number of files: 3,735,070\n",
            "    total number of tokens: 22.10G\n",
            "    total number of sentence fragments: 3.35G\n",
            "\n",
            "    [[ NOTICE ]]\n",
            "    In original data, the source language is `en` and target language is `ko`. However in Korpora,\n",
            "    we change the language pair so that source language is `ko` and target language is `en`.\n",
            "\n",
            "    # License\n",
            "    Open Data. Details in https://opendefinition.org/od/2.1/en/\n",
            "\n",
            "[Korpora] Corpus `open_subtitles` is already installed at /root/Korpora/open_subtitles/en-ko.tmx.gz\n",
            "[Korpora] Corpus `open_subtitles` is already installed at /root/Korpora/open_subtitles/en-ko.tmx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b99xrUsJVnD"
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R1ZUFQPJaHL"
      },
      "source": [
        "def preprocess_sentence(sent):\n",
        "  # 위에서 구현한 함수를 내부적으로 호출\n",
        "  sent = unicode_to_ascii(sent.lower())\n",
        "\n",
        "  # 단어와 구두점 사이에 공백을 만듭니다.\n",
        "  # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
        "  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "\n",
        "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
        "  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
        "\n",
        "  sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "  return sent"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "korean = corpus.train[0:60000].text\n",
        "english = corpus.train[0:60000].pair\n",
        "lines = pd.DataFrame({'src':korean, 'tar':english})\n",
        "print(lines)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfYx9ewpdOqo",
        "outputId": "bae6874c-fa39-40a2-9d32-d7d67c20e9d2"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                     src                                                tar\n",
            "0      폭설이 내리고 우박, 진눈깨비가 퍼부어도 눈보라가 몰아쳐도 강풍이 불고 비바람이 휘...  Through the snow and sleet and hail, through t...\n",
            "1                   우리의 한결같은 심부름꾼 황새 아저씨 가는 길을 그 누가 막으랴!  ever faithful, ever true, nothing stops him, h...\n",
            "2                                          황새 아저씨를 기다리세요        Look out for Mr Stork That persevering chap\n",
            "3                                         찾아와 선물을 주실 거예요     He'll come along and drop a bundle in your lap\n",
            "4                                     가난하든 부자이든 상관이 없답니다    You may be poor or rich It doesn't matter which\n",
            "...                                                  ...                                                ...\n",
            "59995  If you really want to do something for me, the...                   - Oh, God, I can't believe this.\n",
            "59996                                     - I'm leaving.                                     - I'm leaving.\n",
            "59997        I've assessed the situation, and I'm going.                             - Where are you going?\n",
            "59998                             - Where are you going?                                    - Just leaving.\n",
            "59999                                        비디오테이프 반납하러                  I have to return some videotapes.\n",
            "\n",
            "[60000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR-_LHGZJbQr"
      },
      "source": [
        "def load_preprocessed_data():\n",
        "  encoder_input, decoder_input, decoder_target = [], [], []\n",
        "\n",
        "  print(len(korean))\n",
        "\n",
        "  for i in range(len(korean)):\n",
        "\n",
        "    # # source 데이터 전처리\n",
        "    src_line = [w for w in korean[i].split()]\n",
        "    src_line = re.sub('-', '', src_line)\n",
        "\n",
        "    # print(src_line)\n",
        "\n",
        "    # # target 데이터 전처리\n",
        "    tar_line = preprocess_sentence(english[i])\n",
        "    tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
        "    tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
        "\n",
        "    encoder_input.append(src_line)\n",
        "    decoder_input.append(tar_line_in)\n",
        "    decoder_target.append(tar_line_out)\n",
        "\n",
        "    if i == num_samples - 1:\n",
        "      break\n",
        "  return encoder_input, decoder_input, decoder_target"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9g2Vp16Jcrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c389779-0b95-44ee-d0ad-65486e2b817e"
      },
      "source": [
        "# 인코딩 테스트\n",
        "en_sent = u\"Have you had dinner?\"\n",
        "fr_sent = u\"Avez-vous déjà diné?\"\n",
        "print(preprocess_sentence(en_sent))\n",
        "print(preprocess_sentence(fr_sent).encode('utf-8'))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "have you had dinner ?\n",
            "b'avez vous deja dine ?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcP4_sXeJdh7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "8f0fc083-c680-412f-ad0c-5a137b9992d6"
      },
      "source": [
        "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-155-7628cf824f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msents_en_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msents_fra_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msents_fra_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_preprocessed_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-153-edb2a8d8d196>\u001b[0m in \u001b[0;36mload_preprocessed_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# # source 데이터 전처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msrc_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkorean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msrc_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# print(src_line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iC8Bb77JgJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24405eb2-231a-431f-ffc8-3a53d1df0d79"
      },
      "source": [
        "print(sents_en_in[:5])\n",
        "print(sents_fra_in[:5])\n",
        "print(sents_fra_out[:5])"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['폭설이', '내리고', '우박,', '진눈깨비가', '퍼부어도', '눈보라가', '몰아쳐도', '강풍이', '불고', '비바람이', '휘몰아쳐도'], ['우리의', '한결같은', '심부름꾼', '황새', '아저씨', '가는', '길을', '그', '누가', '막으랴!'], ['황새', '아저씨를', '기다리세요'], ['찾아와', '선물을', '주실', '거예요'], ['가난하든', '부자이든', '상관이', '없답니다']]\n",
            "[['<sos>', 'through', 'the', 'snow', 'and', 'sleet', 'and', 'hail', 'through', 'the', 'blizzard', 'through', 'the', 'gales', 'through', 'the', 'wind', 'and', 'through', 'the', 'rain', 'over', 'mountain', 'over', 'plain', 'through', 'the', 'blinding', 'lightning', 'flash', 'and', 'the', 'mighty', 'thunder', 'crash'], ['<sos>', 'ever', 'faithful', 'ever', 'true', 'nothing', 'stops', 'him', 'he', 'll', 'get', 'through', '.'], ['<sos>', 'look', 'out', 'for', 'mr', 'stork', 'that', 'persevering', 'chap'], ['<sos>', 'he', 'll', 'come', 'along', 'and', 'drop', 'a', 'bundle', 'in', 'your', 'lap'], ['<sos>', 'you', 'may', 'be', 'poor', 'or', 'rich', 'it', 'doesn', 't', 'matter', 'which']]\n",
            "[['through', 'the', 'snow', 'and', 'sleet', 'and', 'hail', 'through', 'the', 'blizzard', 'through', 'the', 'gales', 'through', 'the', 'wind', 'and', 'through', 'the', 'rain', 'over', 'mountain', 'over', 'plain', 'through', 'the', 'blinding', 'lightning', 'flash', 'and', 'the', 'mighty', 'thunder', 'crash', '<eos>'], ['ever', 'faithful', 'ever', 'true', 'nothing', 'stops', 'him', 'he', 'll', 'get', 'through', '.', '<eos>'], ['look', 'out', 'for', 'mr', 'stork', 'that', 'persevering', 'chap', '<eos>'], ['he', 'll', 'come', 'along', 'and', 'drop', 'a', 'bundle', 'in', 'your', 'lap', '<eos>'], ['you', 'may', 'be', 'poor', 'or', 'rich', 'it', 'doesn', 't', 'matter', 'which', '<eos>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBNqle5oJg9r"
      },
      "source": [
        "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_en.fit_on_texts(sents_en_in)\n",
        "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
        "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
        "\n",
        "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
        "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
        "\n",
        "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
        "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
        "\n",
        "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
        "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xo3ITQZJh0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e5f492-13b8-45e5-9603-5f02de519639"
      },
      "source": [
        "print(encoder_input.shape)\n",
        "print(decoder_input.shape)\n",
        "print(decoder_target.shape)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33000, 30)\n",
            "(33000, 56)\n",
            "(33000, 56)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGM22-GmJiej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f9e00a6-cd80-4e4f-c03d-78830a5dc1cb"
      },
      "source": [
        "vocab_size_en = len(tokenizer_en.word_index) + 1\n",
        "vocab_size_fra = len(tokenizer_fra.word_index) + 1\n",
        "print(\"영어 단어 집합의 크기 (en): {:d}, 프랑스어 단어 집합의 크기 (spa): {:d}\".format(vocab_size_en, vocab_size_fra))"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 단어 집합의 크기 (en): 53949, 프랑스어 단어 집합의 크기 (spa): 11618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxm9W_PoJjf7"
      },
      "source": [
        "src_to_index = tokenizer_en.word_index\n",
        "index_to_src = tokenizer_en.index_word\n",
        "\n",
        "tar_to_index = tokenizer_fra.word_index\n",
        "index_to_tar = tokenizer_fra.index_word"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AATBjTo8JkMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b038fb-8709-4c79-e951-fa73584a4a15"
      },
      "source": [
        "max_src_len = encoder_input.shape[1]\n",
        "max_tar_len = decoder_input.shape[1]\n",
        "print('source 문장의 최대 길이 :',max_src_len)\n",
        "print('target 문장의 최대 길이 :',max_tar_len)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source 문장의 최대 길이 : 30\n",
            "target 문장의 최대 길이 : 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_NTWBaUJk4i"
      },
      "source": [
        "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
        "tar_vocab_size = len(tokenizer_fra.word_index) + 1"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt0pr-cdJmkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63885cd9-ae42-40e1-d7ea-b80127cced7c"
      },
      "source": [
        "indices = np.arange(encoder_input.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "print(indices)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30194 29994 29393 ...   451 16651 32778]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkzmSVY9J29z"
      },
      "source": [
        "encoder_input = encoder_input[indices]\n",
        "decoder_input = decoder_input[indices]\n",
        "decoder_target = decoder_target[indices]"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W34Y6qmJJ4Bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2abf69b3-c059-4a1e-f1ea-550aa48892eb"
      },
      "source": [
        "encoder_input[30997]"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    1, 51952,  6836,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_SoeJOIJ45D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11fd5403-dcc7-434c-c235-0ea93007866e"
      },
      "source": [
        "decoder_input[30997]"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2,    5,  150, 3652,    1,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lscvHdOXJ5yD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ce1c026-dc46-40a7-dce1-722d97e659c1"
      },
      "source": [
        "decoder_target[30997]"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   5,  150, 3652,    1,    3,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RZNFshbJ6g7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbcf4166-0306-4b15-da29-730107133f8f"
      },
      "source": [
        "n_of_val = int(33000*0.1)\n",
        "print('검증 데이터의 개수 :',n_of_val)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "검증 데이터의 개수 : 3300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14voLCWTJ7PU"
      },
      "source": [
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_39d-h9J8Eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b2ee555-d10f-4440-d05f-64872d7e3aaf"
      },
      "source": [
        "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
        "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
        "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
        "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
        "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
        "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 source 데이터의 크기 : (29700, 30)\n",
            "훈련 target 데이터의 크기 : (29700, 56)\n",
            "훈련 target 레이블의 크기 : (29700, 56)\n",
            "테스트 source 데이터의 크기 : (3300, 30)\n",
            "테스트 target 데이터의 크기 : (3300, 56)\n",
            "테스트 target 레이블의 크기 : (3300, 56)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmmwQfMRJ82S"
      },
      "source": [
        "latent_dim = 50"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moB2bzsLJ9oC"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmhABadkJ-Tc"
      },
      "source": [
        "# 인코더\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(src_vocab_size, latent_dim)(encoder_inputs) # 임베딩 층\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
        "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaEi3nv4J_FS"
      },
      "source": [
        "# 디코더\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(tar_vocab_size, latent_dim) # 임베딩 층\n",
        "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "\n",
        "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "\n",
        "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
        "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzdqwXyLZ_xi"
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N5zH1kZJ_6b"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtLKFJqXKAr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56bb1fbc-179f-4d45-aa34-3bca7785c21d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 50)     2697450     ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 50)     580900      ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " masking_2 (Masking)            (None, None, 50)     0           ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " masking_3 (Masking)            (None, None, 50)     0           ['embedding_3[0][0]']            \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 50),         20200       ['masking_2[0][0]']              \n",
            "                                 (None, 50),                                                      \n",
            "                                 (None, 50)]                                                      \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 50),   20200       ['masking_3[0][0]',              \n",
            "                                 (None, 50),                      'lstm_2[0][1]',                 \n",
            "                                 (None, 50)]                      'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 11618)  592518      ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,911,268\n",
            "Trainable params: 3,911,268\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0TyuHwEKBnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c2ce61b-008c-4893-e2c8-bbce2317c1a2"
      },
      "source": [
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size=128, epochs=50)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "233/233 [==============================] - 47s 131ms/step - loss: 2.3719 - acc: 0.8274 - val_loss: 0.9564 - val_acc: 0.8566\n",
            "Epoch 2/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.9178 - acc: 0.8618 - val_loss: 0.8944 - val_acc: 0.8641\n",
            "Epoch 3/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.8802 - acc: 0.8654 - val_loss: 0.8715 - val_acc: 0.8675\n",
            "Epoch 4/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.8527 - acc: 0.8685 - val_loss: 0.8439 - val_acc: 0.8700\n",
            "Epoch 5/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.8263 - acc: 0.8714 - val_loss: 0.8246 - val_acc: 0.8729\n",
            "Epoch 6/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.8054 - acc: 0.8734 - val_loss: 0.8141 - val_acc: 0.8738\n",
            "Epoch 7/50\n",
            "233/233 [==============================] - 27s 116ms/step - loss: 0.7882 - acc: 0.8750 - val_loss: 0.7988 - val_acc: 0.8756\n",
            "Epoch 8/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.7740 - acc: 0.8767 - val_loss: 0.7924 - val_acc: 0.8760\n",
            "Epoch 9/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.7626 - acc: 0.8779 - val_loss: 0.7861 - val_acc: 0.8770\n",
            "Epoch 10/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.7524 - acc: 0.8789 - val_loss: 0.7787 - val_acc: 0.8778\n",
            "Epoch 11/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.7437 - acc: 0.8797 - val_loss: 0.7836 - val_acc: 0.8779\n",
            "Epoch 12/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.7355 - acc: 0.8804 - val_loss: 0.7708 - val_acc: 0.8787\n",
            "Epoch 13/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.7275 - acc: 0.8811 - val_loss: 0.7767 - val_acc: 0.8786\n",
            "Epoch 14/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.7205 - acc: 0.8817 - val_loss: 0.7835 - val_acc: 0.8775\n",
            "Epoch 15/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.7141 - acc: 0.8822 - val_loss: 0.7751 - val_acc: 0.8769\n",
            "Epoch 16/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.7080 - acc: 0.8827 - val_loss: 0.7696 - val_acc: 0.8783\n",
            "Epoch 17/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.7026 - acc: 0.8832 - val_loss: 0.7770 - val_acc: 0.8788\n",
            "Epoch 18/50\n",
            "233/233 [==============================] - 27s 114ms/step - loss: 0.6977 - acc: 0.8837 - val_loss: 0.7755 - val_acc: 0.8779\n",
            "Epoch 19/50\n",
            "233/233 [==============================] - 27s 114ms/step - loss: 0.6931 - acc: 0.8841 - val_loss: 0.7721 - val_acc: 0.8791\n",
            "Epoch 20/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6889 - acc: 0.8845 - val_loss: 0.7772 - val_acc: 0.8764\n",
            "Epoch 21/50\n",
            "233/233 [==============================] - 27s 114ms/step - loss: 0.6850 - acc: 0.8848 - val_loss: 0.7722 - val_acc: 0.8784\n",
            "Epoch 22/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6813 - acc: 0.8851 - val_loss: 0.7734 - val_acc: 0.8786\n",
            "Epoch 23/50\n",
            "233/233 [==============================] - 28s 121ms/step - loss: 0.6777 - acc: 0.8856 - val_loss: 0.7783 - val_acc: 0.8771\n",
            "Epoch 24/50\n",
            "233/233 [==============================] - 27s 116ms/step - loss: 0.6746 - acc: 0.8859 - val_loss: 0.7798 - val_acc: 0.8784\n",
            "Epoch 25/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6716 - acc: 0.8862 - val_loss: 0.7789 - val_acc: 0.8778\n",
            "Epoch 26/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6685 - acc: 0.8866 - val_loss: 0.7828 - val_acc: 0.8779\n",
            "Epoch 27/50\n",
            "233/233 [==============================] - 27s 116ms/step - loss: 0.6657 - acc: 0.8870 - val_loss: 0.7846 - val_acc: 0.8776\n",
            "Epoch 28/50\n",
            "233/233 [==============================] - 27s 116ms/step - loss: 0.6627 - acc: 0.8873 - val_loss: 0.7849 - val_acc: 0.8771\n",
            "Epoch 29/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6600 - acc: 0.8877 - val_loss: 0.7887 - val_acc: 0.8775\n",
            "Epoch 30/50\n",
            "233/233 [==============================] - 27s 114ms/step - loss: 0.6570 - acc: 0.8880 - val_loss: 0.7917 - val_acc: 0.8769\n",
            "Epoch 31/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6541 - acc: 0.8884 - val_loss: 0.7923 - val_acc: 0.8768\n",
            "Epoch 32/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6511 - acc: 0.8888 - val_loss: 0.7926 - val_acc: 0.8773\n",
            "Epoch 33/50\n",
            "233/233 [==============================] - 27s 116ms/step - loss: 0.6482 - acc: 0.8892 - val_loss: 0.7967 - val_acc: 0.8758\n",
            "Epoch 34/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6450 - acc: 0.8895 - val_loss: 0.7994 - val_acc: 0.8765\n",
            "Epoch 35/50\n",
            "233/233 [==============================] - 27s 116ms/step - loss: 0.6421 - acc: 0.8899 - val_loss: 0.8010 - val_acc: 0.8761\n",
            "Epoch 36/50\n",
            "233/233 [==============================] - 27s 116ms/step - loss: 0.6392 - acc: 0.8902 - val_loss: 0.8024 - val_acc: 0.8766\n",
            "Epoch 37/50\n",
            "233/233 [==============================] - 27s 116ms/step - loss: 0.6360 - acc: 0.8906 - val_loss: 0.8057 - val_acc: 0.8760\n",
            "Epoch 38/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6332 - acc: 0.8910 - val_loss: 0.8080 - val_acc: 0.8752\n",
            "Epoch 39/50\n",
            "233/233 [==============================] - 27s 116ms/step - loss: 0.6300 - acc: 0.8914 - val_loss: 0.8157 - val_acc: 0.8754\n",
            "Epoch 40/50\n",
            "233/233 [==============================] - 27s 116ms/step - loss: 0.6266 - acc: 0.8918 - val_loss: 0.8106 - val_acc: 0.8770\n",
            "Epoch 41/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6234 - acc: 0.8922 - val_loss: 0.8100 - val_acc: 0.8758\n",
            "Epoch 42/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6205 - acc: 0.8925 - val_loss: 0.8179 - val_acc: 0.8752\n",
            "Epoch 43/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6176 - acc: 0.8929 - val_loss: 0.8248 - val_acc: 0.8759\n",
            "Epoch 44/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6148 - acc: 0.8932 - val_loss: 0.8244 - val_acc: 0.8748\n",
            "Epoch 45/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6123 - acc: 0.8937 - val_loss: 0.8327 - val_acc: 0.8733\n",
            "Epoch 46/50\n",
            "233/233 [==============================] - 27s 114ms/step - loss: 0.6096 - acc: 0.8941 - val_loss: 0.8327 - val_acc: 0.8732\n",
            "Epoch 47/50\n",
            "233/233 [==============================] - 27s 116ms/step - loss: 0.6073 - acc: 0.8944 - val_loss: 0.8311 - val_acc: 0.8742\n",
            "Epoch 48/50\n",
            "233/233 [==============================] - 27s 118ms/step - loss: 0.6050 - acc: 0.8948 - val_loss: 0.8309 - val_acc: 0.8739\n",
            "Epoch 49/50\n",
            "233/233 [==============================] - 27s 115ms/step - loss: 0.6027 - acc: 0.8951 - val_loss: 0.8355 - val_acc: 0.8731\n",
            "Epoch 50/50\n",
            "233/233 [==============================] - 27s 117ms/step - loss: 0.6007 - acc: 0.8956 - val_loss: 0.8409 - val_acc: 0.8728\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efec4647450>"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCeLHL7Eaw0g"
      },
      "source": [
        "# 인코더\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9COCiea6ayBE"
      },
      "source": [
        "# 디코더 설계 시작\n",
        "# 이전 시점의 상태를 보관할 텐서\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 훈련 때 사용했던 임베딩 층을 재사용\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "\n",
        "# 모든 시점에 대해서 단어 예측\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO3gY6QVa2yE"
      },
      "source": [
        "# 디코더\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga64fRPtKDZr"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 상태를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>에 해당하는 정수 생성\n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0, 0] = tar_to_index['<sos>']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "\n",
        "  # stop_condition이 True가 될 때까지 루프 반복\n",
        "  # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
        "  while not stop_condition:\n",
        "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    # 예측 결과를 단어로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 단어를 예측 문장에 추가\n",
        "    decoded_sentence += ' '+sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
        "    if (sampled_char == '<eos>' or\n",
        "        len(decoded_sentence) > 50):\n",
        "        stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJTnaYOfKEdz"
      },
      "source": [
        "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq_to_src(input_seq):\n",
        "  sentence = ''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word!=0):\n",
        "      sentence = sentence + index_to_src[encoded_word] + ' '\n",
        "  return sentence\n",
        "\n",
        "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
        "def seq_to_tar(input_seq):\n",
        "  sentence = ''\n",
        "  for encoded_word in input_seq:\n",
        "    if(encoded_word!=0 and encoded_word!=tar_to_index['<sos>'] and encoded_word!=tar_to_index['<eos>']):\n",
        "      sentence = sentence + index_to_tar[encoded_word] + ' '\n",
        "  return sentence"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [ 443, 454, 343, 234, 233]:\n",
        "  input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  \n",
        "  print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
        "  print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
        "  print(\"번역문장 :\",decoded_sentence[1:-5])\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "id": "67VVvofh8SSI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}